"0","set.seed(2019) #set the seed"
"0","n <- names(ktrain) #extract names to build formula"
"0","f <- as.formula(paste('classif ~', paste(n[!n %in% 'classif'], collapse = ' + ')))"
"0","k_indexs <- sample(seq(nrow(ktrain))) #scamble the indexs in order to conduct k-fold"
"0","nss <- c(1,2,3,4,5,10,20,40,45) # range of hidden layer nodes to explore"
"0","ls <- c(.1,.2,.3,.4,.5,.6,.7,.8,.9,1) # range of learning rates to explore"
"0","ls_len <- length(ls) # length of the learning rate, i made it same as nodes"
"0","zero_ls <- rep(0,ls_len) # empty zero vector to make R happy"
"0","train.acc.mat <- data.frame(zero_ls) #initalize to empty vector to make the raw matrix"
"0","test.acc.mat <- data.frame(zero_ls) # ^^^"
"0","# Node amount loop (outter most loop)"
"0","for (s in seq(length(nss))){"
"0","  "
"0","  ns <- nss[s] #extract node number"
"0","  "
"0","  "
"0","  train.acc <- zero_ls # inilize the accuracy vectors"
"0","  test.acc <- zero_ls  # ^^^"
"0","  "
"0","  # Learning Rate Loop (middle loop)"
"0","  for (l in seq(ls_len)){"
"0","    lss <- ls[l] #extract the learning rate"
"0","    "
"0","    # Cross validation loop"
"0","    for (i in seq(11)) {"
"0","        "
"0","        if (i == 1){"
"0","          str <- 1 # initalize start index"
"0","          stp <- 4 # initialize stop index"
"0","        }"
"0","        else{"
"0","          #4 fold cross validation I chose this way bc the math was easier"
"0","          str <- str + 4 "
"0","          stp <- stp + 4"
"0","        }"
"0","      "
"0","      k_in <- k_indexs[str:stp] #Pull out the indexs from the shuffled vector"
"0","      "
"0","      # Subsetting the trianing data "
"0","      fold_cross <- ktrain[k_in,] # Cross validation test set"
"0","      fold_c_truth <- ktrain[k_in,1] # Cross validation test truth"
"0","      fold_train <- ktrain[-k_in,] # Cross-V training data"
"0","      fold_t_truth <- ktrain[-k_in,1] # Cross-V training truth"
"0","    "
"0","      #Note: The ns can be made into multiple layers by c(layer1,layer2)"
"0","                       "
"0","      # Do the THING!               "
"0","      nn <- neuralnet(f,data=fold_train, hidden=ns, learningrate = lss, linear.output = F)"
"0","      "
"0","      "
"0","      # compute train predictions"
"0","      train.pr <- neuralnet::compute(nn,fold_train[,2:ncol(fold_train)])"
"0","      train_result <- round(train.pr$net.result)"
"0","      "
"0","      # find train accuracy and append to vector"
"0","      train.a <- perc_acc(train_result, fold_t_truth,11) #11 cross validation loop ave"
"0","      train.acc[l] <- train.acc[l] + train.a"
"0","    "
"0","      #compute test preditctions"
"0","      test.pr <- neuralnet::compute(nn,fold_cross[,2:ncol(fold_cross)])"
"0","      test_result <- round(test.pr$net.result)"
"0","      "
"0","      #find test accuracy and append to vector"
"0","      test.a <- perc_acc(test_result,fold_c_truth,11) #11 cross validation loop ave"
"0","      test.acc[l] <- test.acc[l] + test.a"
"0","      "
"0","     "
"0","  }"
"0","  }"
"0","  # add the accuracy vectors to their matrixes"
"0","  train.acc.mat <- cbind(train.acc.mat,train.acc) "
"0","  test.acc.mat <- cbind(test.acc.mat,test.acc)"
"0","}"
"0","train.acc.mat <- train.acc.mat[,2:ncol(train.acc.mat)]"
"0","test.acc.mat <- test.acc.mat[,2:ncol(test.acc.mat)]"
