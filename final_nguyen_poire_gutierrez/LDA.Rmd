---
title: "Final - LDA"
author: "Justine Nguyen"
output: html_document
---

```{r}
sessionInfo()
```

```{r 1.setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library

```{r 2.library, warning=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(caret) # for LDA modeling
library(janitor)
library(corrplot)
library(genefilter)
library(ggplot2)
library(reshape2)
```

<br><br>

# Function Definitions

```{r 3.fxnDefinitions}
## FUNCTION FOR BINARIZING THE OUTCOME (drug responsiveness)
binarizeOutcomeFxn <- function(data) 
  {
  outcomeBinary <- ifelse(data[1] == '1', 1, 0)
  data[1] <- as.factor(outcomeBinary)
  
  return(data)
  }
```

<br><br>

# Reading in Cleaned Data

```{r 4.readData, message=FALSE}
# Read in the cleaned expression data
# NOTE: data has features are ROWS when reading it from the flat file.
# Also clean the names of the genes in the expression data
expression <- as.data.frame((read.table("../data/clean_expression.txt", row.names=1 )))
rownames(expression)[1] <- '184A1'# Rename the only integer name
expression <- clean_names(expression)


# Read in the subtype data
subtypes <- read_tsv("../data/clean_subtypes.txt")

# Read in the truth set
truth_set <-  as.data.frame((read.table("../data/clean_training_answers.txt", row.names=1 )))
# Clean row names of truth set
truth_set <- clean_names(truth_set)

# Create merged feature set
featureSet<-cbind(subtypes[,2],t(expression))

# Check dimensions of allthe data read in to see if it was correct
dim(expression)
dim(subtypes)
dim(truth_set)
dim(featureSet)
```

I just checked the dimensions of all the data I read in to see if it was read in correctly.  

<br><br>

# Examining the Variance in the Features

Initially, I wanted to try to model drug responsiveness on the breast cancer cell lines to examine the variance/bias trade-off in different model complexities. I understand the relationship with higher model complexity and increased chances of overfitting the training data, but it would have been a good exercise to go through and build the less complex/ more naive model to compare to a more complex model as a baseline.   

A pitfall of LDA as a classifier is that the predictor variables must be fed into the formula in order for the model to be build. That means that I have to somehow use feature selection to buld the model. My goal was to sort all the genes by their variance and try to create a cut-off for the top most variant genes and use those for my predictors. 

Based on the published information from the authors, they determined that just the subtype alone would be a good predictor for classifying hte drug responsiveness for the cell lines but addining int he gene expression data makes the model more accurate. This makes sense because there is evidence that there are distinct categorizations even within the subtypes. 

An important assumption for an LDA model is that there is no multi-colinearity in the data. Adding in variables with multi-colinearity create biases in the weight for each variable that is used in the model formula. I try to account for that below.   

The first step was to create a matrix with all the variances of each gene across each sample. I then pull out the variances for each quantile in 1% increments. My strategy was to create a model for each drug (12 models total) but optimize how many highest variance features I will use for each model. I will compare the top 1%, 5% and 10% most variant genes across the training sample.  

After pulling the most variant genes (for 1%, 5%, and 10%). I save a subsetted expression set for those top variant genes at different percentages.  

<br>

#### Pulling the most variant genes for feature selection 

```{r 5.varianceSelect}
# Create a variance matrix of the expression data
expVar <- (rowVars(expression))
hist(expVar)
expVar <- as.data.frame(expVar)
names(expVar) <- c('variance')

# Look at the min and max variance in the expression data
paste('max variance:', max(expVar[,1]))
paste('min variance:', min(expVar[,1]))

# Pull the quantiles of the variance matrix by increments of 1%
quantile(expVar$variance, seq(0,1,by=0.01))

# Grab the genes with the top 10 percentile of greatest varaince
top10<- expVar$variance > '0.98099145'
# Save the expression data of the genes with top 10 percentile of greatest variance
top10FeatureSet <- featureSet[,top10]

# Grab the genes with the top 5 percentile of greatest varaince
top5<- expVar$variance > '1.63523217'
# Save the expres'sion data of the genes with top 5 percentile of greatest variance
top5FeatureSet <- featureSet[,top5]

# Grab the genes with the top 1 percentile of greatest varaince
top1<- expVar$variance > '3.57993931'
# Save the expres'sion data of the genes with top 1 percentile of greatest variance
top1FeatureSet <- featureSet[,top1]

```

Above, you can see that in the 18633 possible gene features, most of the genes have a low variance in bin in '0' to '1'. 90% of the genes have a variance of less than 1. That was why I chose 10% of the genes as the highest number of features I will use. I then also picked 5% and 1% just to optimize the model. The idea of using the most variant genes is that the variance across the different cell-lines may explain why a ell line responds to a drug or not. If a gene is unchanged across all cell lines with different drug treatments, then it is unlikely to be able to explain why response changes. As a note, I picked 10% because it had variance greater than 1, but for 5% and 1%, they were arbitrary. I would want to go back later on and somehow come up with a better reasoning of the cut off. But so far, I am looking at smaller subsets of most variant genes to try to avoid multi-colinear predictors AND so I can try to prevent muddling the model with many variables that may not be good in correlating power to drug responsiveness.    

<br>

#### Attempt at handling multi-colinearity of the features

LDA does not handle multi-colinearity very well so I have to somehow handle this. My overall approach to the multi-colinearity problem is to create a correlation matrix of the top variant genes (for each % I am optimizing) and then sum the correlation for that gene compared to all the other rows. Then I am going to determine a threshold in order to remove genes with high multi-colinearity compared to the other filtered high variant genes. I decided to put the threshold at 75% of the summed correlation scores across all other features. That way I will pull up the quantiles and pull genes with summed variances above that threshold out of the expression feature set. In a way, I am further filtering the top most variant genes (1%, 5%, 10%) by trying to remove genes with high correlation against other genes.   

```{r CORRELATION.1perVar}
# Create a correlation matrix of all the genes for the top 1% of features
cor.1<- (cor(top1FeatureSet[3:ncol(top1FeatureSet)]))
cor.1df <- as.data.frame(cor.1)

# Plot the correlation matrix for the 1% top variance genes
corrplot(cor.1, order="FPC", tl.pos = "n", diag = FALSE, type="upper", method="color", tl.cex = 0.5)


## Remove the top 25% most corelated genes from the set of 1% variance genes
varSum.1 <- as.data.frame(matrix(0, nrow =185, ncol= 1))
varSum.1[ , 'gene'] <- NA
varSum.1[,'sumVar'] <- NA
varSum.1$V1 <- NULL

genes.1 <- (row.names(cor.1))

for (i in genes.1){
  count = 1
  sum1 = 0
  for (j in 1:length(genes.1)){
    sum1 = sum1 + abs(cor.1[i, j])
  }
  varSum.1[i, ]<- c(i, sum1) 
  count = count+1
}

varSum.1[,2] <- as.numeric(varSum.1[,2])
summary(varSum.1)
varSum.1 <- na.omit(varSum.1)

for (i in 1:length(genes.1)){
  if (varSum.1[genes.1[i],2] > 42.76){
top1FeatureSet[, genes.1[i]] <- NULL    }
}

top1FeatureSet <- na.omit(top1FeatureSet)

```

Above, I print out the correlation matrix of the top 1% most variant genes in the data set. The diagram is sorted by the most variant genes. You can see in the corners that there are darker pigments of red and blue, which would be genes that highly correlated with other genes. Hopefully, by removing the top 25% of the strongest correlated genes from the top variant set, I am able to better control for multi-colinearity.   

(I am not sure what the most eloquent way for handling multi-colinearity is when you have such large data! A lot of sources I was researching were creating models for colinear genes and looking at the p-value for the predictive power to filer for which variable will be maintained in the model formula... However as you can imagine, it would be very very difficult to build that many models with hundreds of strongly correlated genes. I will just see if this method will be able to partially handle multi-colinear and allow me to have higher predictive power for drug responsiveness.)

I then look at the correlation for all the top 5% most variant genes:  

```{r CORRELATION.5perVar}
# Create a correlation matrix of all the genes for the top 1% of features
cor.5<- (cor(top5FeatureSet[3:ncol(top5FeatureSet)]))
cor.5df <- as.data.frame(cor.5)


corrplot(cor.5, order="FPC", tl.pos = "n", diag = FALSE, type="upper", method="color", tl.cex = 0.5)

varSum.5 <- as.data.frame(matrix(0, nrow =185, ncol= 1))
varSum.5[ , 'gene'] <- NA
varSum.5[,'sumVar'] <- NA
varSum.5$V1 <- NULL

genes.5 <- (row.names(cor.5))

for (i in genes.5){
  count = 1
  sum1 = 0
  for (j in 1:length(genes.1)){
    sum1 = sum1 + abs(cor.5[i, j])
  }
  varSum.5[i, ]<- c(i, sum1) 
  count = count+1
}

varSum.5[,2] <- as.numeric(varSum.5[,2])
summary(varSum.5)
varSum.5 <- na.omit(varSum.5)

for (i in 1:length(genes.5)){
  if (varSum.5[genes.5[i],2] > 43.20){
top5FeatureSet[, genes.5[i]] <- NULL    }
}

top5FeatureSet <- na.omit(top5FeatureSet)

```

I also plot the correlation plot for the correlations of the top 5% most variant genes. You can see that in the tips of the triangle, there are even more genes that are strongly correlated with each other! It makes sense that the more genes I look at the more multi-colinearity could occur. I also filtered the feature set by removing the 25% most correlated genes (based on sum of correlation across all other predictors... same method as above.) 

I continue and perform the same correlation assessment for the top 10% most variant genes:  

```{r CORRELATION.10perVar}
# Create a correlation matrix of all the genes for the top 1% of features
cor.10<- (cor(top10FeatureSet[3:ncol(top10FeatureSet)]))
cor.10df <- as.data.frame(cor.10)

# Look at the 
corrplot(cor.10, order="FPC", tl.pos = "n", diag = FALSE, type="upper", method="color", tl.cex = 0.5)

varSum.10 <- as.data.frame(matrix(0, nrow =185, ncol= 1))
varSum.10[ , 'gene'] <- NA
varSum.10[,'sumVar'] <- NA
varSum.10$V1 <- NULL

genes.10 <- (row.names(cor.10))

for (i in genes.10){
  count = 1
  sum1 = 0
  for (j in 1:length(genes.10)){
    sum1 = sum1 + abs(cor.10[i, j])
  }
  varSum.10[i, ]<- c(i, sum1) 
  count = count+1
}

varSum.10[,2] <- as.numeric(varSum.10[,2])
summary(varSum.10)
varSum.10 <- na.omit(varSum.10)

for (i in 1:length(genes.10)){
  if (varSum.10[genes.10[i],2] > 441.5 ){
top10FeatureSet[, genes.10[i]] <- NULL    }
}

top10FeatureSet <- na.omit(top10FeatureSet)
```

<br><br>

# Optimizing and Training the Models

In this next code chunk, I am creating a data frame with all my cell lines and drug combinations. I am going to append the cross-validation accuracy and the re-training of the model on the training set accuracy to this data frame. This will help me determine which percentage of most variant genes will be better for creating the LDA for that specific drug. 

As a metric for model selection, I am going to use the re-training accuracy (from the train set) to pick which percentrage of variance in genes will be used for the final model. If there is a tie between my three parameters of 1%, 5%, or 10%, I will then choose the model that had higher cross validation error given the tied training accuracy.  

I just prepare the data frame below:  

```{r 6.fileTrainTest}
# Vector with all drug names
drugs <- c('cgc_11047','carboplatin', 'cisplatin', 'gsk1070916', 'gsk1120212', 'gsk461364', 'geldanamycin', 'oxaliplatin', 'pf_3084014', 'pf_3814735', 'pf_4691502', 'paclitaxel')
# Create all combinations of variants tested per drug
variance <- ('10')
results <- cbind(drugs, variance)
variance <- ('5')
results <- rbind(results, cbind(drugs, variance))
variance <- ('1')
results <- rbind(results, cbind(drugs, variance))
# Convert to data frame
results <- as.data.frame(results)

# Sort data frame based on drug
results <- results[order(results$drug),]
# Append column for trianing accuracy 
results[ , 'train_accuracy'] <- NA
# Append column for cross validation accuracy.
results[ , 'CV_accuracy'] <- NA
```

The next section (very large section) is training my LDA model on the 12 drugs - 12 models total. I use LDA with 10-fold cross validation with 10x repeated sampling. I perform this with the 1%, 5% and 10% top variant genes that have 25% of the most correlated genes summed against all other features pulled out. It is also important that the cell line subtype is also a feature that I will use in all my models to predict drug responsiveness.    

I train the model, then I pull out the cross-validation accuracy for pulling the model. I then train on the training set again and pull the training accuracy. I save those values into my ```results``` data table to compare the best paramater is for each drug.  


## MODEL 1 - CGC.11047 DRUG

```{r 7.cgc11047Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cgc11047Data.10 <- as.data.frame(cbind(truth_set$cgc_11047, top10FeatureSet))
names(cgc11047Data.10)[1] <- "outcome"
cgc11047Data.10 <- clean_names(cgc11047Data.10)
cgc11047Data.10 <- binarizeOutcomeFxn(cgc11047Data.10)

# Formula for the predictive model
f.10 = as.formula(paste(names(cgc11047Data.10)[1]," ~ ", paste(names(cgc11047Data.10)[2:ncol(cgc11047Data.10)], collapse= "+")))

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cgc11047.lda.fit.10 = train(f.10, 
                          data=cgc11047Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cgc11047.lda.fit.10
summary(cgc11047.lda.fit.10)

# Predict using the training set again
pred.cgc11047.10 = predict(cgc11047.lda.fit.10, cgc11047Data.10)
pred.table.10<-table(pred.cgc11047.10, cgc11047Data.10$outcome)
pred.table.10
# TEST ACCURACY ON TRAINING DATA
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("train accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cgc_11047" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- cgc11047.lda.fit.10$results[2]
```

```{r 8.cgc11047Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cgc11047Data.5 <- as.data.frame(cbind(truth_set$cgc_11047, top5FeatureSet))
names(cgc11047Data.5)[1] <- "outcome"
cgc11047Data.5 <- clean_names(cgc11047Data.5)
cgc11047Data.5 <- binarizeOutcomeFxn(cgc11047Data.5)

# Formula for the predictive model
f.5 = as.formula(paste(names(cgc11047Data.5)[1]," ~ ", paste(names(cgc11047Data.5)[2:ncol(cgc11047Data.5)], collapse= "+")))

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cgc11047.lda.fit.5 = train(f.5, 
                          data=cgc11047Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cgc11047.lda.fit.5
summary(cgc11047.lda.fit.5)

# Predict using the training set again
pred.cgc11047.5 = predict(cgc11047.lda.fit.5, cgc11047Data.5)
pred.table.5<-table(pred.cgc11047.5, cgc11047Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cgc_11047" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- cgc11047.lda.fit.5$results[2]
```

```{r 9.cgc11047Model, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cgc11047Data.1 <- as.data.frame(cbind(truth_set$cgc_11047, top1FeatureSet))
names(cgc11047Data.1)[1] <- "outcome"
cgc11047Data.1 <- clean_names(cgc11047Data.1)
cgc11047Data.1 <- binarizeOutcomeFxn(cgc11047Data.1)

# Formula for the predictive model
f.1 = as.formula(paste(names(cgc11047Data.1)[1]," ~ ", paste(names(cgc11047Data.1)[2:ncol(cgc11047Data.1)], collapse= "+")))

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cgc11047.lda.fit.1 = train(f.1, 
                          data=cgc11047Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cgc11047.lda.fit.1
summary(cgc11047.lda.fit.1)

# Predict using the training set again
pred.cgc11047.1 = predict(cgc11047.lda.fit.1, cgc11047Data.1)
pred.table.1<-table(pred.cgc11047.1, cgc11047Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cgc_11047" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- cgc11047.lda.fit.1$results[2]
```

<br>

## MODEL 2 - CARBOPLATIN DRUG

```{r 10.carboplatinModel.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
carboplatinData.10 <- as.data.frame(cbind(truth_set$carboplatin, top10FeatureSet))
names(carboplatinData.10)[1] <- "outcome"
carboplatinData.10 <- clean_names(carboplatinData.10)
carboplatinData.10 <- binarizeOutcomeFxn(carboplatinData.10)


# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
carboplatin.lda.fit.10 = train(f.10, 
                          data=carboplatinData.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
carboplatin.lda.fit.10
summary(carboplatin.lda.fit.10)

# Predict using the training set again
pred.carboplatin.10 = predict(carboplatin.lda.fit.10, carboplatinData.10)
pred.table.10<-table(pred.carboplatin.10, carboplatinData.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="carboplatin" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- carboplatin.lda.fit.10$results[2]
```

```{r 11.carboplatinModel.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
carboplatinData.5 <- as.data.frame(cbind(truth_set$carboplatin, top5FeatureSet))
names(carboplatinData.5)[1] <- "outcome"
carboplatinData.5 <- clean_names(carboplatinData.5)
carboplatinData.5 <- binarizeOutcomeFxn(carboplatinData.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
carboplatin.lda.fit.5 = train(f.5, 
                          data=carboplatinData.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
carboplatin.lda.fit.5
summary(carboplatin.lda.fit.5)

# Predict using the training set again
pred.carboplatin.5 = predict(carboplatin.lda.fit.5, carboplatinData.5)
pred.table.5<-table(pred.carboplatin.5, carboplatinData.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="carboplatin" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- carboplatin.lda.fit.5$results[2]

```

```{r 12.carboplatinModel.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
carboplatinData.1 <- as.data.frame(cbind(truth_set$carboplatin, top1FeatureSet))
names(carboplatinData.1)[1] <- "outcome"
carboplatinData.1 <- clean_names(carboplatinData.1)
carboplatinData.1 <- binarizeOutcomeFxn(carboplatinData.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
carboplatin.lda.fit.1 = train(f.1, 
                          data=carboplatinData.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
carboplatin.lda.fit.1
summary(carboplatin.lda.fit.1)

# Predict using the training set again
pred.carboplatin.1 = predict(carboplatin.lda.fit.1, carboplatinData.1)
pred.table.1<-table(pred.carboplatin.1, carboplatinData.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="carboplatin" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- carboplatin.lda.fit.1$results[2]

```

<br>

## MODEL 3 - CISPLATIN DRUG

```{r 13.cisplatinModel.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cisplatinData.10 <- as.data.frame(cbind(truth_set$cisplatin, top10FeatureSet))
names(cisplatinData.10)[1] <- "outcome"
cisplatinData.10 <- clean_names(cisplatinData.10)
cisplatinData.10 <- binarizeOutcomeFxn(cisplatinData.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cisplatin.lda.fit.10 = train(f.10, 
                          data=cisplatinData.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cisplatin.lda.fit.10
summary(cisplatin.lda.fit.10)

# Predict using the training set again
pred.cisplatin.10 = predict(cisplatin.lda.fit.10, cisplatinData.10)
pred.table.10<-table(pred.cisplatin.10, cisplatinData.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cisplatin" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- cisplatin.lda.fit.10$results[2]

```

```{r 14.cisplatinModel.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cisplatinData.5 <- as.data.frame(cbind(truth_set$cisplatin, top5FeatureSet))
names(cisplatinData.5)[1] <- "outcome"
cisplatinData.5 <- clean_names(cisplatinData.5)
cisplatinData.5 <- binarizeOutcomeFxn(cisplatinData.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cisplatin.lda.fit.5 = train(f.5, 
                          data=cisplatinData.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cisplatin.lda.fit.5
summary(cisplatin.lda.fit.5)

# Predict using the training set again
pred.cisplatin.5 = predict(cisplatin.lda.fit.5, cisplatinData.5)
pred.table.5<-table(pred.cisplatin.5, cisplatinData.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cisplatin" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- cisplatin.lda.fit.5$results[2]

```

```{r 15.cisplatinModel.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
cisplatinData.1 <- as.data.frame(cbind(truth_set$cisplatin, top1FeatureSet))
names(cisplatinData.1)[1] <- "outcome"
cisplatinData.1 <- clean_names(cisplatinData.1)
cisplatinData.1 <- binarizeOutcomeFxn(cisplatinData.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
cisplatin.lda.fit.1 = train(f.1, 
                          data=cisplatinData.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
cisplatin.lda.fit.1
summary(cisplatin.lda.fit.1)

# Predict using the training set again
pred.cisplatin.1 = predict(cisplatin.lda.fit.1, cisplatinData.1)
pred.table.1<-table(pred.cisplatin.1, cisplatinData.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="cisplatin" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- cisplatin.lda.fit.1$results[2]

```

<br>

# MODEL 4 - GSK1070916 DRUG

```{r 16.gsk1070916Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1070916Data.10 <- as.data.frame(cbind(truth_set$gsk1070916, top10FeatureSet))
names(gsk1070916Data.10)[1] <- "outcome"
gsk1070916Data.10 <- clean_names(gsk1070916Data.10)
gsk1070916Data.10 <- binarizeOutcomeFxn(gsk1070916Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1070916.lda.fit.10 = train(f.10, 
                          data=gsk1070916Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1070916.lda.fit.10
summary(gsk1070916.lda.fit.10)

# Predict using the training set again
pred.gsk1070916.10 = predict(gsk1070916.lda.fit.10, gsk1070916Data.10)
pred.table.10<-table(pred.gsk1070916.10, gsk1070916Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1070916" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1070916.lda.fit.10$results[2]

```

```{r 17.gsk1070916Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1070916Data.5 <- as.data.frame(cbind(truth_set$gsk1070916, top5FeatureSet))
names(gsk1070916Data.5)[1] <- "outcome"
gsk1070916Data.5 <- clean_names(gsk1070916Data.5)
gsk1070916Data.5 <- binarizeOutcomeFxn(gsk1070916Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1070916.lda.fit.5 = train(f.5, 
                          data=gsk1070916Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1070916.lda.fit.5
summary(gsk1070916.lda.fit.5)

# Predict using the training set again
pred.gsk1070916.5 = predict(gsk1070916.lda.fit.5, gsk1070916Data.5)
pred.table.5<-table(pred.gsk1070916.5, gsk1070916Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1070916" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1070916.lda.fit.5$results[2]

```

```{r 18.gsk1070916Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1070916Data.1 <- as.data.frame(cbind(truth_set$gsk1070916, top1FeatureSet))
names(gsk1070916Data.1)[1] <- "outcome"
gsk1070916Data.1 <- clean_names(gsk1070916Data.1)
gsk1070916Data.1 <- binarizeOutcomeFxn(gsk1070916Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1070916.lda.fit.1 = train(f.1, 
                          data=gsk1070916Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1070916.lda.fit.1
summary(gsk1070916.lda.fit.1)

# Predict using the training set again
pred.gsk1070916.1 = predict(gsk1070916.lda.fit.1, gsk1070916Data.1)
pred.table.1<-table(pred.gsk1070916.1, gsk1070916Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1070916" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1070916.lda.fit.1$results[2]

```

<br>

# MODEL 5 - GSK1120212 DRUG

```{r 19.gsk1120212Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1120212Data.10 <- as.data.frame(cbind(truth_set$gsk1120212, top10FeatureSet))
names(gsk1120212Data.10)[1] <- "outcome"
gsk1120212Data.10 <- clean_names(gsk1120212Data.10)
gsk1120212Data.10 <- binarizeOutcomeFxn(gsk1120212Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1120212.lda.fit.10 = train(f.10, 
                          data=gsk1120212Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1120212.lda.fit.10
summary(gsk1120212.lda.fit.10)

# Predict using the training set again
pred.gsk1120212.10 = predict(gsk1120212.lda.fit.10, gsk1120212Data.10)
pred.table.10<-table(pred.gsk1120212.10, gsk1120212Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1120212" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1120212.lda.fit.10$results[2]

```

```{r 20.gsk1120212Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1120212Data.5 <- as.data.frame(cbind(truth_set$gsk1120212, top5FeatureSet))
names(gsk1120212Data.5)[1] <- "outcome"
gsk1120212Data.5 <- clean_names(gsk1120212Data.5)
gsk1120212Data.5 <- binarizeOutcomeFxn(gsk1120212Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1120212.lda.fit.5 = train(f.5, 
                          data=gsk1120212Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1120212.lda.fit.5
summary(gsk1120212.lda.fit.5)

# Predict using the training set again
pred.gsk1120212.5 = predict(gsk1120212.lda.fit.5, gsk1120212Data.5)
pred.table.5<-table(pred.gsk1120212.5, gsk1120212Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1120212" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1120212.lda.fit.5$results[2]

```

```{r 21.gsk1120212Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk1120212Data.1 <- as.data.frame(cbind(truth_set$gsk1120212, top1FeatureSet))
names(gsk1120212Data.1)[1] <- "outcome"
gsk1120212Data.1 <- clean_names(gsk1120212Data.1)
gsk1120212Data.1 <- binarizeOutcomeFxn(gsk1120212Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk1120212.lda.fit.1 = train(f.1, 
                          data=gsk1120212Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk1120212.lda.fit.1
summary(gsk1120212.lda.fit.1)

# Predict using the training set again
pred.gsk1120212.1 = predict(gsk1120212.lda.fit.1, gsk1120212Data.1)
pred.table.1<-table(pred.gsk1120212.1, gsk1120212Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk1120212" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- gsk1120212.lda.fit.1$results[2]

```

<br>

# MODEL 6 - GSK461364 DRUG

```{r 22.gsk461364Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk461364Data.10 <- as.data.frame(cbind(truth_set$gsk461364, top10FeatureSet))
names(gsk461364Data.10)[1] <- "outcome"
gsk461364Data.10 <- clean_names(gsk461364Data.10)
gsk461364Data.10 <- binarizeOutcomeFxn(gsk461364Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk461364.lda.fit.10 = train(f.10, 
                          data=gsk461364Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk461364.lda.fit.10
summary(gsk461364.lda.fit.10)

# Predict using the training set again
pred.gsk461364.10 = predict(gsk461364.lda.fit.10, gsk461364Data.10)
pred.table.10<-table(pred.gsk461364.10, gsk461364Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk461364" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- gsk461364.lda.fit.10$results[2]

```

```{r 23.gsk461364Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk461364Data.5 <- as.data.frame(cbind(truth_set$gsk461364, top5FeatureSet))
names(gsk461364Data.5)[1] <- "outcome"
gsk461364Data.5 <- clean_names(gsk461364Data.5)
gsk461364Data.5 <- binarizeOutcomeFxn(gsk461364Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk461364.lda.fit.5 = train(f.5, 
                          data=gsk461364Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk461364.lda.fit.5
summary(gsk461364.lda.fit.5)

# Predict using the training set again
pred.gsk461364.5 = predict(gsk461364.lda.fit.5, gsk461364Data.5)
pred.table.5<-table(pred.gsk461364.5, gsk461364Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk461364" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- gsk461364.lda.fit.5$results[2]
```

```{r 24.gsk461364Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
gsk461364Data.1 <- as.data.frame(cbind(truth_set$gsk461364, top1FeatureSet))
names(gsk461364Data.1)[1] <- "outcome"
gsk461364Data.1 <- clean_names(gsk461364Data.1)
gsk461364Data.1 <- binarizeOutcomeFxn(gsk461364Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
gsk461364.lda.fit.1 = train(f.1, 
                          data=gsk461364Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
gsk461364.lda.fit.1
summary(gsk461364.lda.fit.1)

# Predict using the training set again
pred.gsk461364.1 = predict(gsk461364.lda.fit.1, gsk461364Data.1)
pred.table.1<-table(pred.gsk461364.1, gsk461364Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="gsk461364" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- gsk461364.lda.fit.1$results[2]
```

<br>

# MODEL 7 - GELDANAMYCIN DRUG

```{r 25.geldanamycinModel.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
geldanamycinData.10 <- as.data.frame(cbind(truth_set$geldanamycin, top10FeatureSet))
names(geldanamycinData.10)[1] <- "outcome"
geldanamycinData.10 <- clean_names(geldanamycinData.10)
geldanamycinData.10 <- binarizeOutcomeFxn(geldanamycinData.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
geldanamycin.lda.fit.10 = train(f.10, 
                          data=geldanamycinData.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
geldanamycin.lda.fit.10
summary(geldanamycin.lda.fit.10)

# Predict using the training set again
pred.geldanamycin.10 = predict(geldanamycin.lda.fit.10, geldanamycinData.10)
pred.table.10<-table(pred.geldanamycin.10, geldanamycinData.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="geldanamycin" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- geldanamycin.lda.fit.10$results[2]
```

```{r 26.geldanamycinModel.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
geldanamycinData.5 <- as.data.frame(cbind(truth_set$geldanamycin, top5FeatureSet))
names(geldanamycinData.5)[1] <- "outcome"
geldanamycinData.5 <- clean_names(geldanamycinData.5)
geldanamycinData.5 <- binarizeOutcomeFxn(geldanamycinData.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
geldanamycin.lda.fit.5 = train(f.5, 
                          data=geldanamycinData.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
geldanamycin.lda.fit.5
summary(geldanamycin.lda.fit.5)

# Predict using the training set again
pred.geldanamycin.5 = predict(geldanamycin.lda.fit.5, geldanamycinData.5)
pred.table.5<-table(pred.geldanamycin.5, geldanamycinData.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="geldanamycin" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- geldanamycin.lda.fit.5$results[2]

```

```{r 27.geldanamycinModel.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
geldanamycinData.1 <- as.data.frame(cbind(truth_set$geldanamycin, top1FeatureSet))
names(geldanamycinData.1)[1] <- "outcome"
geldanamycinData.1 <- clean_names(geldanamycinData.1)
geldanamycinData.1 <- binarizeOutcomeFxn(geldanamycinData.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
geldanamycin.lda.fit.1 = train(f.1, 
                          data=geldanamycinData.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
geldanamycin.lda.fit.1
summary(geldanamycin.lda.fit.1)

# Predict using the training set again
pred.geldanamycin.1 = predict(geldanamycin.lda.fit.1, geldanamycinData.1)
pred.table.1<-table(pred.geldanamycin.1, geldanamycinData.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="geldanamycin" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- geldanamycin.lda.fit.1$results[2]

```

<br>

# MODEL 8 - OXALIPLATIN DRUG

```{r 28.oxaliplatinModel.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
oxaliplatinData.10 <- as.data.frame(cbind(truth_set$oxaliplatin, top10FeatureSet))
names(oxaliplatinData.10)[1] <- "outcome"
oxaliplatinData.10 <- clean_names(oxaliplatinData.10)
oxaliplatinData.10 <- binarizeOutcomeFxn(oxaliplatinData.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
oxaliplatin.lda.fit.10 = train(f.10, 
                          data=oxaliplatinData.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
oxaliplatin.lda.fit.10
summary(oxaliplatin.lda.fit.10)

# Predict using the training set again
pred.oxaliplatin.10 = predict(oxaliplatin.lda.fit.10, oxaliplatinData.10)
pred.table.10<-table(pred.oxaliplatin.10, oxaliplatinData.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="oxaliplatin" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- oxaliplatin.lda.fit.10$results[2]

```

```{r 29.oxaliplatinModel.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
oxaliplatinData.5 <- as.data.frame(cbind(truth_set$oxaliplatin, top5FeatureSet))
names(oxaliplatinData.5)[1] <- "outcome"
oxaliplatinData.5 <- clean_names(oxaliplatinData.5)
oxaliplatinData.5 <- binarizeOutcomeFxn(oxaliplatinData.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
oxaliplatin.lda.fit.5 = train(f.5, 
                          data=oxaliplatinData.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
oxaliplatin.lda.fit.5
summary(oxaliplatin.lda.fit.5)

# Predict using the training set again
pred.oxaliplatin.5 = predict(oxaliplatin.lda.fit.5, oxaliplatinData.5)
pred.table.5<-table(pred.oxaliplatin.5, oxaliplatinData.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="oxaliplatin" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- oxaliplatin.lda.fit.5$results[2]

```

```{r 30.oxaliplatinModel.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
oxaliplatinData.1 <- as.data.frame(cbind(truth_set$oxaliplatin, top1FeatureSet))
names(oxaliplatinData.1)[1] <- "outcome"
oxaliplatinData.1 <- clean_names(oxaliplatinData.1)
oxaliplatinData.1 <- binarizeOutcomeFxn(oxaliplatinData.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
oxaliplatin.lda.fit.1 = train(f.1, 
                          data=oxaliplatinData.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
oxaliplatin.lda.fit.1
summary(oxaliplatin.lda.fit.1)

# Predict using the training set again
pred.oxaliplatin.1 = predict(oxaliplatin.lda.fit.1, oxaliplatinData.1)
pred.table.1<-table(pred.oxaliplatin.1, oxaliplatinData.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="oxaliplatin" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- oxaliplatin.lda.fit.1$results[2]

```

<br>

# MODEL 9 - PF.3084014 DRUG

```{r 31.pf_3084014Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3084014Data.10 <- as.data.frame(cbind(truth_set$pf_3084014, top10FeatureSet))
names(pf_3084014Data.10)[1] <- "outcome"
pf_3084014Data.10 <- clean_names(pf_3084014Data.10)
pf_3084014Data.10 <- binarizeOutcomeFxn(pf_3084014Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3084014.lda.fit.10 = train(f.10, 
                          data=pf_3084014Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3084014.lda.fit.10
summary(pf_3084014.lda.fit.10)

# Predict using the training set again
pred.pf_3084014.10 = predict(pf_3084014.lda.fit.10, pf_3084014Data.10)
pred.table.10<-table(pred.pf_3084014.10, pf_3084014Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3084014" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3084014.lda.fit.10$results[2]

```

```{r 32.pf_3084014Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3084014Data.5 <- as.data.frame(cbind(truth_set$pf_3084014, top5FeatureSet))
names(pf_3084014Data.5)[1] <- "outcome"
pf_3084014Data.5 <- clean_names(pf_3084014Data.5)
pf_3084014Data.5 <- binarizeOutcomeFxn(pf_3084014Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3084014.lda.fit.5 = train(f.5, 
                          data=pf_3084014Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3084014.lda.fit.5
summary(pf_3084014.lda.fit.5)

# Predict using the training set again
pred.pf_3084014.5 = predict(pf_3084014.lda.fit.5, pf_3084014Data.5)
pred.table.5<-table(pred.pf_3084014.5, pf_3084014Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3084014" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3084014.lda.fit.5$results[2]

```

```{r 33.pf_3084014Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3084014Data.1 <- as.data.frame(cbind(truth_set$pf_3084014, top1FeatureSet))
names(pf_3084014Data.1)[1] <- "outcome"
pf_3084014Data.1 <- clean_names(pf_3084014Data.1)
pf_3084014Data.1 <- binarizeOutcomeFxn(pf_3084014Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3084014.lda.fit.1 = train(f.1, 
                          data=pf_3084014Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3084014.lda.fit.1
summary(pf_3084014.lda.fit.1)

# Predict using the training set again
pred.pf_3084014.1 = predict(pf_3084014.lda.fit.1, pf_3084014Data.1)
pred.table.1<-table(pred.pf_3084014.1, pf_3084014Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3084014" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3084014.lda.fit.1$results[2]

```

<br>

# MODEL 10 - PF.3814735 DRUG

```{r 34.pf_3814735Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3814735Data.10 <- as.data.frame(cbind(truth_set$pf_3814735, top10FeatureSet))
names(pf_3814735Data.10)[1] <- "outcome"
pf_3814735Data.10 <- clean_names(pf_3814735Data.10)
pf_3814735Data.10 <- binarizeOutcomeFxn(pf_3814735Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3814735.lda.fit.10 = train(f.10, 
                          data=pf_3814735Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3814735.lda.fit.10
summary(pf_3814735.lda.fit.10)

# Predict using the training set again
pred.pf_3814735.10 = predict(pf_3814735.lda.fit.10, pf_3814735Data.10)
pred.table.10<-table(pred.pf_3814735.10, pf_3814735Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3814735" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3814735.lda.fit.10$results[2]
```

```{r 35.pf_3814735Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3814735Data.5 <- as.data.frame(cbind(truth_set$pf_3814735, top5FeatureSet))
names(pf_3814735Data.5)[1] <- "outcome"
pf_3814735Data.5 <- clean_names(pf_3814735Data.5)
pf_3814735Data.5 <- binarizeOutcomeFxn(pf_3814735Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3814735.lda.fit.5 = train(f.5, 
                          data=pf_3814735Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3814735.lda.fit.5
summary(pf_3814735.lda.fit.5)

# Predict using the training set again
pred.pf_3814735.5 = predict(pf_3814735.lda.fit.5, pf_3814735Data.5)
pred.table.5<-table(pred.pf_3814735.5, pf_3814735Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3814735" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3814735.lda.fit.5$results[2]

```

```{r 36.pf_3814735Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_3814735Data.1 <- as.data.frame(cbind(truth_set$pf_3814735, top1FeatureSet))
names(pf_3814735Data.1)[1] <- "outcome"
pf_3814735Data.1 <- clean_names(pf_3814735Data.1)
pf_3814735Data.1 <- binarizeOutcomeFxn(pf_3814735Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_3814735.lda.fit.1 = train(f.1, 
                          data=pf_3814735Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_3814735.lda.fit.1
summary(pf_3814735.lda.fit.1)

# Predict using the training set again
pred.pf_3814735.1 = predict(pf_3814735.lda.fit.1, pf_3814735Data.1)
pred.table.1<-table(pred.pf_3814735.1, pf_3814735Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_3814735" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- pf_3814735.lda.fit.1$results[2]

```

<br>

# MODEL 11 - PF.4691502 DRUG

```{r 37.pf_4691502Model.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_4691502Data.10 <- as.data.frame(cbind(truth_set$pf_4691502, top10FeatureSet))
names(pf_4691502Data.10)[1] <- "outcome"
pf_4691502Data.10 <- clean_names(pf_4691502Data.10)
pf_4691502Data.10 <- binarizeOutcomeFxn(pf_4691502Data.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_4691502.lda.fit.10 = train(f.10, 
                          data=pf_4691502Data.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_4691502.lda.fit.10
summary(pf_4691502.lda.fit.10)

# Predict using the training set again
pred.pf_4691502.10 = predict(pf_4691502.lda.fit.10, pf_4691502Data.10)
pred.table.10<-table(pred.pf_4691502.10, pf_4691502Data.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_4691502" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- pf_4691502.lda.fit.10$results[2]

```

```{r 38.pf_4691502Model.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_4691502Data.5 <- as.data.frame(cbind(truth_set$pf_4691502, top5FeatureSet))
names(pf_4691502Data.5)[1] <- "outcome"
pf_4691502Data.5 <- clean_names(pf_4691502Data.5)
pf_4691502Data.5 <- binarizeOutcomeFxn(pf_4691502Data.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_4691502.lda.fit.5 = train(f.5, 
                          data=pf_4691502Data.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_4691502.lda.fit.5
summary(pf_4691502.lda.fit.5)

# Predict using the training set again
pred.pf_4691502.5 = predict(pf_4691502.lda.fit.5, pf_4691502Data.5)
pred.table.5<-table(pred.pf_4691502.5, pf_4691502Data.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_4691502" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- pf_4691502.lda.fit.5$results[2]

```

```{r 39.pf_4691502Model.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
pf_4691502Data.1 <- as.data.frame(cbind(truth_set$pf_4691502, top1FeatureSet))
names(pf_4691502Data.1)[1] <- "outcome"
pf_4691502Data.1 <- clean_names(pf_4691502Data.1)
pf_4691502Data.1 <- binarizeOutcomeFxn(pf_4691502Data.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
pf_4691502.lda.fit.1 = train(f.1, 
                          data=pf_4691502Data.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
pf_4691502.lda.fit.1
summary(pf_4691502.lda.fit.1)

# Predict using the training set again
pred.pf_4691502.1 = predict(pf_4691502.lda.fit.1, pf_4691502Data.1)
pred.table.1<-table(pred.pf_4691502.1, pf_4691502Data.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="pf_4691502" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- pf_4691502.lda.fit.1$results[2]

```

<br>

# MODEL 12 - PACLITAXEL DRUG

```{r 40.paclitaxelModel.10, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
paclitaxelData.10 <- as.data.frame(cbind(truth_set$paclitaxel, top10FeatureSet))
names(paclitaxelData.10)[1] <- "outcome"
paclitaxelData.10 <- clean_names(paclitaxelData.10)
paclitaxelData.10 <- binarizeOutcomeFxn(paclitaxelData.10)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
paclitaxel.lda.fit.10 = train(f.10, 
                          data=paclitaxelData.10, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
paclitaxel.lda.fit.10
summary(paclitaxel.lda.fit.10)

# Predict using the training set again
pred.paclitaxel.10 = predict(paclitaxel.lda.fit.10, paclitaxelData.10)
pred.table.10<-table(pred.paclitaxel.10, paclitaxelData.10$outcome)
pred.table.10
acc <- (pred.table.10[1,1]+pred.table.10[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="paclitaxel" & results[,2]=="10"))
results[ind, 3] <- acc
results[ind, 4] <- paclitaxel.lda.fit.10$results[2]

```

```{r 41.paclitaxelModel.5, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
paclitaxelData.5 <- as.data.frame(cbind(truth_set$paclitaxel, top5FeatureSet))
names(paclitaxelData.5)[1] <- "outcome"
paclitaxelData.5 <- clean_names(paclitaxelData.5)
paclitaxelData.5 <- binarizeOutcomeFxn(paclitaxelData.5)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
paclitaxel.lda.fit.5 = train(f.5, 
                          data=paclitaxelData.5, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
paclitaxel.lda.fit.5
summary(paclitaxel.lda.fit.5)

# Predict using the training set again
pred.paclitaxel.5 = predict(paclitaxel.lda.fit.5, paclitaxelData.5)
pred.table.5<-table(pred.paclitaxel.5, paclitaxelData.5$outcome)
pred.table.5
acc <- (pred.table.5[1,1]+pred.table.5[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="paclitaxel" & results[,2]=="5"))
results[ind, 3] <- acc
results[ind, 4] <- paclitaxel.lda.fit.5$results[2]

```

```{r 42.paclitaxelModel.1, warning=FALSE}
# Bind the outcome to the feature set
# Clean the column names
# Bimarize the outcome values
paclitaxelData.1 <- as.data.frame(cbind(truth_set$paclitaxel, top1FeatureSet))
names(paclitaxelData.1)[1] <- "outcome"
paclitaxelData.1 <- clean_names(paclitaxelData.1)
paclitaxelData.1 <- binarizeOutcomeFxn(paclitaxelData.1)

# Train the model with 10 fold cross validation with 10x repeated sampling using an LDA model
paclitaxel.lda.fit.1 = train(f.1, 
                          data=paclitaxelData.1, 
                          method="lda",
                          trControl = trainControl(method = "repeatedcv", repeats=10))
# Print the model
paclitaxel.lda.fit.1
summary(paclitaxel.lda.fit.1)

# Predict using the training set again
pred.paclitaxel.1 = predict(paclitaxel.lda.fit.1, paclitaxelData.1)
pred.table.1<-table(pred.paclitaxel.1, paclitaxelData.1$outcome)
pred.table.1
acc <- (pred.table.1[1,1]+pred.table.1[2,2])/25
paste("accuracy:", acc, "%")

# Find index in results table for drug and variance then append train and CV accuracy
ind <- which((results[,1]=="paclitaxel" & results[,2]=="1"))
results[ind, 3] <- acc
results[ind, 4] <- paclitaxel.lda.fit.1$results[2]

```

<br>

```{r 43trainTestResults}
results
```

After training and creating 12 models for the drugs, I print the table with the drug and the % top variant genes to compute the model in order to look at the training and cross-validation error. Again, I am going to pick the best percentage based on the model's ability to perform well by predicting on the training set. If there is a tie in the parameter for training accuracy, I will break the tie based on the cross-validation accuracy.

I then plot the training accuracy and cross -validation accuracy for each model that I had built. This will be used to choose the best model to run on the test set.

```{r 43.2plotResults}
uniqueDrugs <- unique(as.vector(results$drugs))

results_long <- melt(results, id = "variance")

ggplot(results_long, 
       aes(x=variance, y=value, color = variable)) + 
  geom_point() + 
  facet_wrap(~results$drugs) + 
  ylab(NULL) + 
  theme(axis.text.y = element_blank(),   
        axis.ticks.y = element_blank(), 
        axis.line = element_line(size = 0.5, 
                                 linetype = "solid")) 
```


| Drug        |% Variant genes for model|
| :---------: |:-----------------------:|
| cgc11047    |         1               |
| carboplatin |         10              |
| cisplatin   |         1               |
| gsk1070916  |          1              |
| gsk1120212  |           10            |
| gsk461364   |              5          |
| gelanamycin |               10        |
| oxaliplatin |                  1      |
| pf.3084014  |                   1     |
| pf.3814735  |             5           |
| pf.4691502  |              1          |
| paclitaxel  |               1         |

<br><br>

# Running the Models through the Test Set

#### Reading in the test set

```{r 44testReadIn, message=FALSE}
### Reading in the data:
test_expr <- as.data.frame(t(read.table("../data/clean_test_expression.txt", row.names=1)))
# Read in the subtype data
test_subs <- read_tsv("../data/clean_test_subtypes.txt")

testProbMap <- read_csv("../data/rand_sub_cont.csv")

testProb <- (read_csv("../data/scoring_and_test_set_id_mappings.csv", col_names=TRUE))
testProb[ , 'modProb'] <- NA
```

Above I just read in the test set and the ID mappings file so I can create my own prediction file. 

<br>

#### Subsetting the test set for relevant features

Before I can train the test set on the selected models for the 12 drugs... I first have to subset the test expression data to match the features that were selected for training the model. I subset the test data for the three parameters because there was at least 1 drug that used each percentage of top variants.  

```{r 45subset1Per}
testFt <- cbind(test_subs[,2], (test_expr))
testFt.1 <- testFt[,top1]

for (i in 1:length(genes.1)){
  if (varSum.1[genes.1[i],2] > 42.76){
    testFt.1[, genes.1[i]] <- NULL    
    }
}

testFt.1 <- na.omit(testFt.1)

testFt.1 <- clean_names(testFt.1)
```

```{r 46subset5Per}
testFt.5 <- testFt[,top5]

for (i in 1:length(genes.5)){
  if (varSum.5[genes.5[i],2] > 43.20){
    testFt.5[, genes.5[i]] <- NULL    
    }
}

testFt.5 <- na.omit(testFt.5)

testFt.5 <- clean_names(testFt.5)
```

```{r 47subset10Per}
testFt.10 <- testFt[,top10]

for (i in 1:length(genes.10)){
  if (varSum.10[genes.10[i],2] > 441.5){
    testFt.10[, genes.10[i]] <- NULL    
    }
}

testFt.10 <- na.omit(testFt.10)

testFt.10 <- clean_names(testFt.10)
```

<br>

I then run a predict of the test expression set data and the subtype through the models that I had built.  

### Testing MODEL 1 - CGC_11047 DRUG

```{r 48cgc11047Test}
cgc11047.t1 <- predict(cgc11047.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(cgc11047.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="CGC-11047"))
  testProb[ind, 5] <- cgc11047.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="CGC-11047"))
  testProb[ind, 5] <- cgc11047.t1[i,2]
  }
}

```

<br>

### Testing MODEL 2 - CARBOPLATIN DRUG

```{r 49carboplatinTest}
carboplatin.t10 <- predict(carboplatin.lda.fit.10,testFt.10, type="prob")
cycle <- as.list(rownames(carboplatin.t10))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="Carboplatin"))
  testProb[ind, 5] <- carboplatin.t10[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="Carboplatin"))
  testProb[ind, 5] <- carboplatin.t10[i,2]
  }
}
```

<br>

### Testing MODEL 3 - CISPLATIN DRUG

```{r 50cisplatinTest}
cisplatin.t1 <- predict(cisplatin.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(cisplatin.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="Cisplatin"))
  testProb[ind, 5] <- cisplatin.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="Cisplatin"))
  testProb[ind, 5] <- cisplatin.t1[i,2]
  }
}
```

<br>

### Testing MODEL 4 - GSK1070916 DRUG

```{r 51gsk1070916Test}
gsk1070916.t1 <- predict(gsk1070916.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(gsk1070916.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="GSK1070916"))
  testProb[ind, 5] <- gsk1070916.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="GSK1070916"))
  testProb[ind, 5] <- gsk1070916.t1[i,2]
  }
}
```

<br>

### Testing MODEL 5 - GSK1120212 DRUG

```{r 52gsk1120212Test}
gsk1120212.t10 <- predict(gsk1120212.lda.fit.10,testFt.10, type="prob")
cycle <- as.list(rownames(gsk1120212.t10))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="GSK1120212"))
  testProb[ind, 5] <- gsk1120212.t10[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="GSK1120212"))
  testProb[ind, 5] <- gsk1120212.t10[i,2]
  }
}
```

<br>

### Testing MODEL 6 - GSK461364 DRUG

```{r 53gsk461364Test}
gsk461364.t5 <- predict(gsk461364.lda.fit.5,testFt.5, type="prob")
cycle <- as.list(rownames(gsk461364.t5))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="GSK461364"))
  testProb[ind, 5] <- gsk461364.t5[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="GSK461364"))
  testProb[ind, 5] <- gsk461364.t5[i,2]
  }
}
```

<br>

### Testing MODEL 7 - GELDANAMYCIN DRUG

```{r 54geldanamycinTest}
geldanamycin.t10 <- predict(geldanamycin.lda.fit.10,testFt.10, type="prob")
cycle <- as.list(rownames(geldanamycin.t10))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="Geldanamycin"))
  testProb[ind, 5] <- geldanamycin.t10[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="Geldanamycin"))
  testProb[ind, 5] <- geldanamycin.t10[i,2]
  }
}
```

<br>

### Testing MODEL 8 - OXALIPLATIN DRUG

```{r 55oxaliplatinTest}
oxaliplatin.t1 <- predict(oxaliplatin.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(oxaliplatin.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="Oxaliplatin"))
  testProb[ind, 5] <- oxaliplatin.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="Oxaliplatin"))
  testProb[ind, 5] <- oxaliplatin.t1[i,2]
  }
}
```

<br>

### Testing MODEL 9 - PF_3084014 DRUG

```{r 56pf_3084014Test}
pf_3084014.t1 <- predict(pf_3084014.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(pf_3084014.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="PF-3084014"))
  testProb[ind, 5] <- pf_3084014.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="PF-3084014"))
  testProb[ind, 5] <- pf_3084014.t1[i,2]
  }
}
```

<br>

### Testing MODEL 10 - PF_3814735 DRUG

```{r 57pf_3814735Test}
pf_3814735.t5 <- predict(pf_3814735.lda.fit.5,testFt.5, type="prob")
cycle <- as.list(rownames(pf_3814735.t5))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="PF-3814735"))
  testProb[ind, 5] <- pf_3814735.t5[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="PF-3814735"))
  testProb[ind, 5] <- pf_3814735.t5[i,2]
  }
}
```

<br>

### Testing MODEL 11 - PF_4691502 DRUG 

```{r 58pf_4691502Test}
pf_4691502.t1 <- predict(pf_4691502.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(pf_4691502.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="PF-4691502"))
  testProb[ind, 5] <- pf_4691502.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="PF-4691502"))
  testProb[ind, 5] <- pf_4691502.t1[i,2]
  }
}
```

<br>

### Testing MODEL 12 - PACLITAXEL DRUG

```{r 59paclitaxelTest}
paclitaxel.t1 <- predict(paclitaxel.lda.fit.1,testFt.1, type="prob")
cycle <- as.list(rownames(paclitaxel.t1))

for (i in 1:length(cycle)){
  if (cycle[i] == "X600MPE"){
  ind <- which((testProb[,1]== "600MPE" & testProb[,2]=="Paclitaxel"))
  testProb[ind, 5] <- paclitaxel.t1[i,2]
  }
  else{
  ind <- which((testProb[,1]== cycle[i] & testProb[,2]=="Paclitaxel"))
  testProb[ind, 5] <- paclitaxel.t1[i,2]
  }
}
```

<br>

#### Writing predicitons out to submit

I then write out the probabilities of drug response that my models predicted for each of the new test objects (drug and cell line given an expression data set and the cell line subtype)

```{r 60writePredictions}
## Write out predictions to CSV to submit to Kaggle :)

newGuess <- cbind(testProbMap[,1],testProb[,5])
names(newGuess)[2]<- "value"

write.csv(as.matrix(newGuess), file = "LDA_predictions.csv", row.names=FALSE)
```

<br><br>

# Model Assessment for LDA

In the first model that I submitted to Kaggle, I selected the top 1% of most variant genes along with the subtype and trained all the drugs with LDA using 10-fold 10x repeated cross validation. Kaggle gave me an area under the ROC  of 0.60749. I was just looking at whether I could build a model with LDA that would do better than chance alone. (AND IT DID !!)

I next had to handle the problem with the genes that I had selected for. There was too much multicolineariry. For my second model, I improved upon the first by taking out 25% of the genes from each top variant gene set based on the sum of that gene's correlation across all genes. It is a naive approach to handling multicolinearity. But I guess that a large assumption is that genes that are multicollinear are multicollinear with a lot of genes. (in hindsight maybe not the best method?) I train using the same parameters for the top 1%, 5% and 10% variant genes and pick the best model formula (hinging on the number of features I feed into the formula), based on the performance of running the model through the training set. If there was a tie in my parameter I used the cross validation accuracy to break the tie. After running my model with the test data, Kaggle gave me back a public score of 0.64086, meaning that this method was able to improve my model.

For this project, I was initially taken by the amount of data, just because there was so much expression data since each drug-cell line combination was sequenced, but actually, we are super data poor because there are not a lot of observations that we are training and cross validating with. If I were to re-do this project using and LDA method, I would most likely use lasso or ridge regression to decrease the number of features. I would stil use a threshold and pull the most variant genes across the training data, but then use either methods to reduce the dimensions of my potential features. Surprisingly, even with this simple of a model (for such complex data), we are stil able to model something better than chance (but I guess I will see after the final results are shown on Kaggle.)

<br><br><br><br>
